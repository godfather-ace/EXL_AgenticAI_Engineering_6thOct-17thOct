{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02e87d8f",
   "metadata": {},
   "source": [
    "### Install the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d88d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index llama-index-llms-groq llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e97237",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "772d0d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import(\n",
    "    Settings, \n",
    "    VectorStoreIndex, \n",
    "    SimpleDirectoryReader\n",
    ")\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5134b250",
   "metadata": {},
   "source": [
    "### Loading the GROQ and HF_TOKEN APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98162f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d57c0e9",
   "metadata": {},
   "source": [
    "### Defining the LLM and Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe439d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Groq(model = \"llama-3.1-8b-instant\")\n",
    "embed_model = HuggingFaceEmbedding(model_name = \"BAAI/bge-small-en-v1.5\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133bed7c",
   "metadata": {},
   "source": [
    "### Load the data for implementing RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4da853",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"sample_data\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670145e7",
   "metadata": {},
   "source": [
    "### Index and Query the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ee303",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50ba1568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-13 19:19:14,794 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensors in Perception provide real-time information about the environment, allowing the AI agent to determine what to do next. This information is essential for the AI agent to successfully explore its surroundings and take actions that lead to the achievement of its goals.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the purpose of Sensors in Perception of an AI agent\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d963476f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
