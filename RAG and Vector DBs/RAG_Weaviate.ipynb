{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75ac9061",
   "metadata": {},
   "source": [
    "### Install the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d8227db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U weaviate-client llama-index-vector-stores-weaviate -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9bdb66",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b9f80d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import(\n",
    "    Settings, \n",
    "    VectorStoreIndex, \n",
    "    StorageContext,\n",
    "    SimpleDirectoryReader\n",
    ")\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.vector_stores.weaviate import WeaviateVectorStore\n",
    "from dotenv import load_dotenv\n",
    "import weaviate\n",
    "from weaviate.classes.init import Auth\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2ab752",
   "metadata": {},
   "source": [
    "### Initialize the APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f20d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# initializing Groq and Weaviate APIs\n",
    "GROQ_API_KEY = os.environ[\"GROQ_API_KEY\"]\n",
    "URL = os.environ[\"WEAVIATE_URL\"]\n",
    "APIKEY = os.environ[\"WEAVIATE_API_KEY\"]\n",
    "\n",
    "# Connect to a Weaviate cluster sandbox instance, Use REST URL and API Key\n",
    "client = weaviate.connect_to_weaviate_cloud(\n",
    "    cluster_url = URL,\n",
    "    auth_credentials = Auth.api_key(APIKEY)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99b47d1",
   "metadata": {},
   "source": [
    "### LLM and Embedding Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e5e4248",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Groq(model = \"llama-3.1-8b-instant\")\n",
    "embed_model = HuggingFaceEmbedding(model_name = \"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b2ce99",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce2be950",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"sample_data\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac36c52d",
   "metadata": {},
   "source": [
    "### Load data in Weaviate Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6121ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = WeaviateVectorStore(\n",
    "    weaviate_client = client, index_name = \"RAGWeaviate\"\n",
    ")\n",
    "storage_context = StorageContext.from_defaults(vector_store = vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context = storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596ea1e6",
   "metadata": {},
   "source": [
    "### Querying the stored data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb762235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-13 21:55:27,500 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What are the different challenges in Copilots?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b33501b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While AI Copilots have the potential to revolutionize various sectors, they also face several challenges. One of the primary difficulties is ensuring the accuracy and reliability of the information they provide. This is particularly crucial in situations where the Copilot's responses may have significant consequences.\n",
      "\n",
      "Another challenge is the potential for bias in the Copilot's knowledge base and decision-making processes. If the data used to train the Copilot is biased, the Copilot may perpetuate and amplify these biases, leading to unfair or discriminatory outcomes.\n",
      "\n",
      "Additionally, there is a risk of over-reliance on Copilots, which can lead to a decline in human skills and critical thinking abilities. This can be particularly problematic in situations where human judgment and expertise are essential.\n",
      "\n",
      "Furthermore, the development and maintenance of a Copilot's knowledge base can be a significant challenge. The Copilot's ability to learn and adapt to new information and situations is crucial, but this also requires a significant amount of data and computational resources.\n",
      "\n",
      "Finally, there are also concerns about the security and privacy of the data used by Copilots. As Copilots become more integrated into our daily lives, there is a growing need to ensure that the data they use is secure and protected from unauthorized access.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
